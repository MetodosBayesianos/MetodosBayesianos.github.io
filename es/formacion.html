<!DOCTYPE html>
  <html>
    <head>
      <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.2/css/all.css" integrity="sha384-oS3vJWv+0UjzBfQzYUhtDYW+Pj2yciDJxpsK1OYPAYjqT085Qq/1cq5FLXAZQ7Ay" crossorigin="anonymous">
      <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
      <link href="../css/materialize.css" type="text/css" rel="stylesheet" media="screen,projection"/>
      <link type="text/css" rel="stylesheet" href="../css/materialize.min.css"  media="screen,projection"/>
      <title>Métodos</title>
      <link rel="icon" href="logos/favicon.png" type="image/x-icon">
      <!--Let browser know website is optimized for mobile-->
      <link rel="stylesheet" href="../css/others.css">
      <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    </head>

    <body>
        <!-- BEGIN HEADER -->
        <ul id="dropdown0" class="dropdown-content">
            <li><a href=""></a></li>
            <li><a href="../es/index.html">Español</a></li>
            <li><a href="../en/index.html">English</a></li>
        </ul>
        <ul id="dropdown1" class="dropdown-content">
            <li><a href=""></a></li>
            <li><a href="../es/index.html">Español</a></li>
            <li><a href="../en/index.html">English</a></li>
        </ul>

        <nav class="deep-orange" role="navigation" style="position:fixed">
            <div class="nav-wrapper container"><a id="logo-container" href="../es/index.html" class="brand-logo"><em>Métodos</em></a>
            <ul class="right hide-on-med-and-down">
                <li><a href="../es/fundamental.html"><b>Elementos</b></a></li>
                <li><a href="../es/comunidad.html"><b>Comunidad</b></a></li>
                <li><a href="../es/aplicaciones.html"><b>Aplicaciones</b></a></li>
                <li><a href="../es/formacion.html"><b>Formación</b></a></li>
                <!--<li><a href="../es/personal.html"><b>Personal</b></a></li>-->
                <!--<li><a href="../es/competencia.html"><b>Competencia</b></a></li>-->
                <li><a href="../es/sede.html"><b>Contacto</b></a></li>
                <!--<li><a class="dropdown-button" href="#!" data-target="dropdown0"><i class="fa fa-language"></i></a></li>-->
            </ul>
        </nav>

        <nav class="deep-orange" role="navigation">
            <ul id="nav-mobile" class="sidenav">
                <!--<li><a class="dropdown-button" href="#!" data-target="dropdown1"><i class="fa fa-language"></i></a></li>-->
                <li><a href="../es/index.html">Métodos Bayesianos</a></li>
                <li><a href=""></a></li>
                <li><a href="../es/fundamental.html">&#x2022; Elementos</a></li>
                <li><a href="../es/comunidad.html">&#x2022; Comunidad</a></li>
                <li><a href="../es/aplicaciones.html">&#x2022; Aplicaciones</a></li>
                <li><a href="../es/formacion.html">&#x2022; Formación</a></li>
                <!--<li><a href="../es/personal.html">&#x2022; Personal</a></li>-->
                <!--<li><a href="../es/competencia.html">&#x2022; Competencia</a></li>-->
                <li><a href="../es/sede.html">&#x2022; Contacto</a></li>
            </ul>
            <a href="#" data-target="nav-mobile" class="sidenav-trigger"><i class="material-icons">menu</i></a>
            </div>
        </nav>
        <!-- END HEADER -->


        <div class="section no-pad-bot" id="index-banner">
            <div class="container" >
            <br><br>

                <h4> Inferencia Bayesiana Causal 1 (IBC1.2024.2)</h4>

                La materia <code>Inferencia Bayesiana Causal 1</code> se imparte como optativa de forma paralela en las licenciaturas de ciencias de datos de la Escuela de Ciencia y Tecnología de la UNSAM y en las licenciatura de ciencia de datos, ciencias de la computación y posgrado de Facultad de Ciencias Exactas y Naturales, UBA.

                <br>

                <table>
                  <tr>
                    <td width="50%" align="center"><img src="https://github.com/glandfried/images/blob/master/logos/ecyt.jpeg" width="250"/></td>
                    <td width="50%" align="center"><img src="https://github.com/glandfried/images/blob/master/logos/UNSAM_blanco.png" width="250"/></td>
                  </tr>
                  <tr>
                    <td width="50%" align="center"><b>Campus Migueletes - EscuelaCyT</b></td>
                    <td width="50%" align="center"><b>Universidad Nacional de San Martín - Argentina</b></td>
                  </tr>
                </table>

                  <br>

                <table>
                  <tr>
                    <td width="50%" align="center"><img src="https://github.com/glandfried/images/blob/master/logos/fcen.png" width="250"/></td>
                    <td width="50%" align="center"><img src="https://github.com/glandfried/images/blob/master/logos/UBA2_blanco.jpg" width="250"/></td>
                  </tr>
                  <tr>
                    <td width="50%" align="center"><b>Pabellón 0 + Inf - FacultadCEN</b></td>
                    <td width="50%" align="center"><b>Universidad Nacional de Buenos Aires - Argentina</b></td>
                  </tr>
                </table>


                <h4>Objetivos.</h4>

                <p>
                Esta materia está enfocada en la evaluación de argumentos causales alternativos mediante la (aproximación a) la aplicación estricta de las reglas de la probabilidad, el sistema de razonamiento en contextos de incertidumbre. La materia tiene por principal objetivo revisar los métodos desarrollados en las últimas décadas para:

                <ul>
                <li>&#x2022; Especificar matemáticamente los argumentos causales expresados en lenguaje natural mediante métodos gráficos intuitivos</li>
                <li>&#x2022; Precisar cómo la estructura causal influye en el flujo de inferencia entre las variables del modelo.</li>
                <li>&#x2022; Identificar el efecto causal entre variables de un modelo causal en base de datos observacionales (sin intervenciones).</li>
                <li>&#x2022; Diseñar experimentos que permitan evaluar teorías causales alternativos</li>
                <li>&#x2022; Seleccionar decisiones óptimas en ciclos de acción-percepción con una naturaleza oculta (simulada).</li>
                </ul>

                El problema real detrás de este problema de conocimiento es responder preguntas esenciales como <strong>¿Qué acciones generan bienestar?</strong>.

                </p>

                <h4>Marco Conceptual</h4>

                <p>

                <strong>Definición de Inferencia</strong>. Las "verdades" son proposiciones válidas para todas las personas. Las ciencias con datos deben validar sus proposiciones (hipótesis) en sistemas naturales abiertos. ¿Tiene sentido hablar de "verdad" si justamente tenemos incertidumbre respecto de su valor real? Al menos podemos evitar mentir: no afirmar más de lo que se sabe (maximizando incertidumbre) sin ocultar todo aquello que sí se sabe (dada la información disponible o restricciones).

                <br>

                <strong>Definición de Bayes</strong>. Evaluación de todo el espacio de hipótesis mediante la (aproximación a la) aplicación estricta de las reglas de la probabilidad: preservar la creencia previa que sigue siendo compatible con los datos (regla del producto) y predecir con la contribución de todas las hipótesis (regla de la suma). Debido al costo computacional de las reglas de la probabilidad, durante el siglo 20 propusieron una gran cantidad criterios arbitrarios de selección de hipótesis, que genera siempre efectos secundarios indeseados como ocurre con el overfitting. Afortunadamente, la aplicación estricta de las reglas de la probabilidad no exhiben estos problemas. Si lo hicieran, no tendríamos aún un sistema de razonamiento para contexto de incertidumbre.

                <br>

                <strong>Definición de Causal</strong>. El problema real de todo organismo vivo es orientar el ciclo de acción-percepción con la naturaleza en favor de su reproducción, supervivencia y bienestar. Los problemas del conocimiento científico obtienen su relevancia y jerarquía de los objetivos que persigue alcanzar. Luego de una percepción evaluamos los argumentos causales alternativos maximizando la incertidumbre dada la información disponible, y antes de actuar seleccionamos la acción minimizando la incertidumbre esperada en relación al objetivo que perseguimos.

                </p>

                <h4>Programa</h4>

                <h5>Primera parte</h5>

                <h6>Unidad 1. Introducción a la especificación y evaluación de argumentos causales</h6>

                <ul>
                <li>&#x2022; Explicación causal. Creencias honestas. Reglas de razonamiento en contextos de incertidumbre. Métodos gráficos de especificación de argumentos causales.</li>
                <li>&#x2022; La naturaleza generativa de los argumentos causales. Evaluación de modelos causales alternativos. Ejemplos identificables y no identificables.</li>
                <li>&#x2022; Modelos conjugados. Emergencia del overfitting por selección y balance natural por evaluación. Ejemplo con modelos polinomiales de complejidad creciente.</li>
                <li>&#x2022; Bibliografía sugerida: Bishop 2013 (1-4). Bishop 2006 (1.1-1.3, 2.1-2.3, 3.3-3.4) Otras: Jaynes (paper), Samaja (3.1-3.4), Klimovsky (4), Jaynes (paper)</li>
                </ul>

                <h6>Unidad 2. Sorpresa: el problema de la comunicación con la realidad</h6>

                <ul>
                <li>&#x2022; Niveles de base empírica. La estructura invariante del dato. El isomorfismo con los sistemas de comunicación emisor-receptor de la teoría de la información.</li>
                <li>&#x2022; Evaluación de sistemas de comunicación alternativos en base a su tasa de predicción en el tiempo, expresada en órdenes de magnitud. Entropía y divergencia.</li>
                <li>&#x2022; Especificación de modelos mediante factor graphs. Descomposición de las reglas de la probabilidad como pasaje de mensajes entre los nodos de las red causal.</li>
                <li>&#x2022; Bibliografía sugerida:  MacKay (1.1, 2.4-6, 4.1), Kelly (paper). Otras: Klimovsky (2), Samaja (3.5, 3.6.2-5).</li>
                </ul>

                <h6> Unidad 3. Estructuras causales dinámicas (teorías) y flujo de inferencia.</h6>

                <ul>
                <li>&#x2022; Estructuras causales dinámicas (teorías). Su especificación mediante gates. Los niveles de razonamiento causal: asociacional, intervencional y contrafactual.</li>
                <li>&#x2022; Flujo de inferencia en teorías causales: pipe, fork, collider. Apertura y cierre de flujos de inferencia entre regiones de la red causal (d-separation).</li>
                <li>&#x2022; Los conceptos de potential outcome y do-operator. El efecto de las intervenciones: truncated factorization. Buenos y malos controles. Ejemplos varios.</li>
                <li>&#x2022; Bibliografía sugerida. Winn (paper), Bishop 2006 (8.2-8.2.2, 8.4-8.4.4, 8.4.7). Neal (2.1, 3, 4.1), Pearl (1).</li>
                </ul>

                <h6>Unidad 4. Estimación pasiva de efectos causales.</h6>

                <ul>
                <li>&#x2022; Enfoques de estimación de efecto causal: adjustment formula, inverse probability weighting, propensity scores</li>
                <li>&#x2022; Métodos para predicción de contrafactuales: twin networks. Método principal para estimación de efectos causales: el criterio backdoor.</li>
                <li>&#x2022; Otros criterios: frontdoor y do-calculus. Ejemplos de identificación de variables de control. Alternativas: deconfounder, variables instrumentales y otras.</li>
                <li>&#x2022; Bibliografía sugerida. Pearl (3,6-7), Hernán (parte I), Cinelli (paper), Neal (4, 6, 7.5-7.6).</li>
                </ul>

                <h5>Segunda parte</h5>

                <h6> Unidad 5. Acción-percepción: el problema de la interacción con la realidad</h6>

                <ul>
                <li>&#x2022; Persistencia de la vida fuera del equilibrio. Intercambio acción-percepción agente-ambiente. El intento por minimizar la sorpresa esperada.</li>
                <li>&#x2022; Reformulación ergódica de la teoría de utilidad esperada. Planificación como inferencia. Evaluación de acciones mediante pseudo-posteriors.</li>
                <li>&#x2022; Control óptimo en Partial Observed Markov Decision Process (POMDP). Ejemplos de selección de acciones. Valor de la información.</li>
                <li>&#x2022; Bibliografía: Parr (1-3), Schrodinger (4-7),  Peters (paper), Levine (1-2), Pearl (4). Otras: Koller (21)</li>
                </ul>

                <h6> Unidad 6. Evaluación activa de argumentos causales.</h6>

                <ul>
                <li>&#x2022; Evaluación de argumentos causales como un juego de interacción acción-percepción con el ambiente. Métodos de Monte Carlo para evaluar teorías.</li>
                <li>&#x2022; Ejemplos de evaluación de modelos causales a través de datos obtenidos por interacción con una simulador causal subyacente oculto.</li>
                <li>&#x2022; Planificación del diseño experimental. La emergencia de la estrategia falsacionista como comportamiento óptimo.</li>
                <li>&#x2022; Bibliografía sugerida. Kass (paper), Pearl (7,9). Hernán (parte II)</li>
                </ul>

                <h6>Unidad 7. Inferencia causal en series temporales.</h6>

                <ul>
                <li>&#x2022; Modelos de historia completa. Problemas de usar el último posterior como prior del siguiente evento. Propagación de la información por toda la red histórica causal.</li>
                <li>&#x2022; Estimación de efecto causal por simulación de contrafactuales. Intervenciones en series temporales. Monte Carlo para series temporales.</li>
                <li>&#x2022; Evaluación de modelos causales alternativos. Apuestas óptimas en deportes: criterio Kelly, fractional Kelly y otros criterios.</li>
                <li>&#x2022; Bibliografía sugerida. Brodersen (paper), Dangauthier (paper), Bishop (13.2.3-13.2.4, 13.3), Hernán (parte II).</li>
                </ul>

                <h6> Unidad 8. Isomorfismo probabilidad-evolución y hackatón "apuestas de vida".</h6>

                <ul>
                <li>&#x2022; Isomorfismo entre las ecuaciones fundamentales de la teoría de la probabilidad (teorema de Bayes) y la teoría de la evoluición (replicator dynamic).</li>
                <li>&#x2022; Las emergencia de las variantes que reducen las fluctuaciones por diversificación individual, cooperación, especialización cooperativa y heterogeneidad.</li>
                <li>&#x2022; Presentación de una competencia de inferencia, intervención, apuestas e intercambios de recursos. Cierre y conclusiones.</li>
                <li>&#x2022; Bibliografía sugerida. Czegel (paper).</li>
                </ul>

                <h4> Bibliografía</h4>

                <p>
                Bibliografía en links, en `github.com/glandfried/biblio/releases/tag/teca`, Sci-hub o Libgen.
                </p>

                <ul>
                <li>&#x2022; Bishop. Pattern recognition and machine learning. Springer; 2006</li>
                <li>&#x2022; Levine S. Reinforcement learning and control as probabilistic inference: Tutorial and review. arXiv. 2018.</li>
                <li>&#x2022; Parr T, Pezzulo G, Friston KJ. Active Inference. MIT Press; 2022</li>
                <li>&#x2022; Pearl J. Causality. Cambridge university press; 2009.</li>
                <li>&#x2022; Peters O. The ergodicity problem in economics. Nature Physics. 2019.</li>
                <li>&#x2022; Winn J. Causality with gates. In: Artificial Intelligence and Statistics. PMLR; 2012.</li>
                </ul>

                <h5> Complementaria:</h5>

                <ul>
                <li>&#x2022; Bishop. Model-based machine learning. Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences. 2013</li>
                <li>&#x2022; Brodersen KH, Gallusser F, Koehler J, Remy N, Scott SL. Inferring causal impact using Bayesian structural time-series models. The Annals of Applied Statistics. 2015;</li>
                <li>&#x2022; Chopin N, Papaspiliopoulos O, et al. An introduction to sequential Monte Carlo. Vol. 4. Springer; 2020.</li>
                <li>&#x2022; Cinelli C, Forney A, Pearl J. A crash course in good and bad controls. Sociological Methods & Research. 2022</li>
                <li>&#x2022; Czégel D, Giaffar H, Tenenbaum JB, Szathmáry E. Bayes and Darwin: How replicator populations implement Bayesian computations. BioEssays. 2022.</li>
                <li>&#x2022; Dangauthier P, Herbrich R, Minka T, Graepel T. Trueskill through time: Revisiting the history of chess. In: Advances in Neural Information Processing Systems; 2008</li>
                <li>&#x2022; Gronau QF, Sarafoglou A, Matzke D, Ly A, Boehm U, Marsman M, et al. A tutorial on bridge sampling. Journal of mathematical psychology. 2017.</li>
                <li>&#x2022; Hernán MA, Robins JM. Causal inference: What if. 2020.</li>
                <li>&#x2022; Jaynes ET. Bayesian methods: General background; 1984.</li>
                <li>&#x2022; Kass RE, Raftery AE. Bayes factors. Journal of the American Statistical Association. 1995.</li>
                <li>&#x2022; Kelly jr JL. A New Interpretation of Information Rate. Bell System Technical Journal. 1956</li>
                <li>&#x2022; Klimovsky G. Las desventuras del conocimiento científico; 1994
                Koller D, Friedman N. Probabilistic graphical models: principles and techniques. MIT press; 2009.</li>
                <li>&#x2022; MacKay DJ. Information theory, inference and learning algorithms. Cambridge university press; 2003.</li>
                <li>&#x2022; McElreath R. Statistical rethinking: A Bayesian course with examples in R and Stan. 2020</li>
                <li>&#x2022; Neal. Introduction to causal inference. Course Lecture Notes (draft). 2020;</li>
                <li>&#x2022; Perrakis K, Ntzoufras I, Tsionas EG. On the use of marginal posteriors in marginal likelihood estimation via importance sampling. Computational Statistics & Data Analysis. 2014.</li>
                <li>&#x2022; Popper K. La lógica de la investigación científica; 1967.</li>
                <li>&#x2022; Samaja J. Epistemologı́a y metodología: elementos para una teoría de la investigación científica. EUDEBA; 1999.</li>
                <li>&#x2022; Schrodinger E. ¿Qué es la vida?. Espasa-Calpe. 1948.</li>
                <li>&#x2022; Vousden W, Farr WM, Mandel I. Dynamic temperature selection for parallel tempering in Markov chain Monte Carlo simulations. Monthly Notices of the Royal Astronomical Society. 2018</li>
                </ul>


            </div>

        <br>
        <br>
        <br>
        <br>


        </div>


        <!--Footer-->
        <nav class="deep-orange" role="navigation" style="background-color:#1a1a1a; height:10%">
            <div class="nav-wrapper container">
                <ul class="social-links">
                    <div class="footer" >
                    <li><a href="mailto:metodosbayesianos@proton.me"><i class="fas fa-envelope"></i></a></li>
                    </div>
                </ul>
            </div>
        </nav>

        <!--JavaScript at end of body for optimized loading-->
        <script src="https://code.jquery.com/jquery-2.1.1.min.js"></script>
        <script src="../js/materialize.js"></script>
        <script src="../js/init.js"></script>
        <script>
            $('.dropdown-button').dropdown({
                inDuration: 300,
                outDuration: 225,
                constrain_width: false, // Does not change width of dropdown to that of the activator
                gutter: 0, // Spacing from edge
                alignment: 'left' // Displays dropdown with edge aligned to the left of button
                }
            );
        </script>
    </body>  

  </html>
 
